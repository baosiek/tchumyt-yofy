{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Identity, Module\n",
    "from collections import OrderedDict\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(v):\n",
    "    return v is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(v, d):\n",
    "    return v if exists(v) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heinsen_associative_scan_log(log_coeffs, log_values):\n",
    "    a_star = log_coeffs.cumsum(dim = 1)\n",
    "    log_h0_plus_b_star = (log_values - a_star).logcumsumexp(dim = 1)\n",
    "    log_h = a_star + log_h0_plus_b_star\n",
    "    return log_h.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return torch.where(x >= 0, x + 0.5, x.sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_g(x):\n",
    "    return torch.where(x >= 0, (F.relu(x) + 0.5).log(), -F.softplus(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class minGRU(Module):\n",
    "    def __init__(self, dim, expansion_factor = 1., proj_out = None):\n",
    "        super().__init__()\n",
    "\n",
    "        dim_inner = int(dim * expansion_factor)\n",
    "        proj_out = default(proj_out, expansion_factor != 1.)\n",
    "\n",
    "        self.to_hidden_and_gate = Linear(dim, dim_inner * 2, bias = False)\n",
    "        self.to_out = Linear(dim_inner, dim, bias = False) if proj_out else Identity()\n",
    "\n",
    "    def forward(self, x, prev_hidden = None, return_next_prev_hidden = False):\n",
    "        seq_len = x.shape[1]\n",
    "        hidden, gate = self.to_hidden_and_gate(x).chunk(2, dim = -1)\n",
    "\n",
    "        if seq_len == 1:\n",
    "            # handle sequential\n",
    "\n",
    "            hidden = g(hidden)\n",
    "            gate = gate.sigmoid()\n",
    "            out = torch.lerp(prev_hidden, hidden, gate) if exists(prev_hidden) else (hidden * gate)\n",
    "        else:\n",
    "            # parallel\n",
    "\n",
    "            log_coeffs = -F.softplus(gate)\n",
    "\n",
    "            log_z = -F.softplus(-gate)\n",
    "            log_tilde_h = log_g(hidden)\n",
    "            log_values = log_z + log_tilde_h\n",
    "\n",
    "            if exists(prev_hidden):\n",
    "                log_values = torch.cat((prev_hidden.log(), log_values), dim = 1)\n",
    "                log_coeffs = F.pad(log_coeffs, (0, 0, 1, 0))\n",
    "\n",
    "            out = heinsen_associative_scan_log(log_coeffs, log_values)\n",
    "            out = out[:, -seq_len:]\n",
    "\n",
    "        next_prev_hidden = out[:, -1:]\n",
    "\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        if not return_next_prev_hidden:\n",
    "            return out\n",
    "\n",
    "        return out, next_prev_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size: int = 8\n",
    "seq_length: int = 4\n",
    "batch_size: int = 2\n",
    "vocabulary_size: int = 50274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the Multihead attention layer\n",
    "multihead_attn = torch.nn.MultiheadAttention(\n",
    "    embed_dim=hidden_size,\n",
    "    num_heads=4,\n",
    "    dropout=0.5,\n",
    "    bias=False,\n",
    "    batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gru = minGRU(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1), dtype=torch.int32))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2), dtype=torch.int32))\n",
    "\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embeddings(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = min_gru(x, return_next_prev_hidden=True)\n",
    "\n",
    "to_att = out + hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_atten, _  = multihead_attn(to_att, to_att, to_att)\n",
    "with_atten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = nn.LayerNorm(hidden_size)\n",
    "with_atten = norm(with_atten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (dense1): Linear(in_features=8, out_features=1000, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (dense2): Linear(in_features=1000, out_features=5000, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (output): Linear(in_features=5000, out_features=50274, bias=True)\n",
       "  (outact): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(hidden_size, 1000)),\n",
    "    ('act1', nn.ReLU()),\n",
    "    ('dense2', nn.Linear(1000, 5000)),\n",
    "    ('act2', nn.ReLU()),\n",
    "    ('output', nn.Linear(5000, vocabulary_size)),\n",
    "    ('outact', nn.Sigmoid()),\n",
    "]))\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 50274])\n",
      "tensor([[2.0210e-05, 1.9131e-05, 2.0274e-05,  ..., 1.9674e-05, 1.9835e-05,\n",
      "         2.0532e-05],\n",
      "        [2.0561e-05, 1.9077e-05, 2.0153e-05,  ..., 1.9848e-05, 1.9829e-05,\n",
      "         1.9613e-05]])\n",
      "tensor([42963, 22670])\n"
     ]
    }
   ],
   "source": [
    "final = mlp(with_atten)\n",
    "print(final.shape)\n",
    "with torch.no_grad():\n",
    "    final = torch.softmax(final[:, -1, :], dim=-1)\n",
    "print(final)\n",
    "label = torch.argmax(final, dim=-1)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      " strips\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "ll = label.tolist()\n",
    "print(len(ll))\n",
    "w1 = tokenizer.decode([label.tolist()[1]])\n",
    "print(w1)\n",
    "print(len(label.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
