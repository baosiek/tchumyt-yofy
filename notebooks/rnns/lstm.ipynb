{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import urllib.request\n",
    "import tiktoken\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 357726\n"
     ]
    }
   ],
   "source": [
    "# Gets the verdict\n",
    "url: str = \"https://www.gutenberg.org/ebooks/67237.txt.utf-8\"\n",
    "urllib.request.urlretrieve(url, \"books/the-verdict.txt\")\n",
    "\n",
    "# Initializes the string that will contain the loaded text above\n",
    "raw_text: str = None\n",
    "\n",
    "# Reads the loaded text\n",
    "with open(\"books/the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Logs the metadata of the text\n",
    "print(f\"Total number of characters: {len(raw_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 97421\n",
      "Vocabulary size: 50257\n"
     ]
    }
   ],
   "source": [
    "# Initializes the tokenizer\n",
    "tokenizer: tiktoken.core.Encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Runs it on the raw text\n",
    "tokens = tokenizer.encode(raw_text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "print(f\"Vocabulary size: {tokenizer.n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size set to: 50257\n"
     ]
    }
   ],
   "source": [
    "# The below parameters define the shape of the embedding layer\n",
    "vocabulary_size: int = tokenizer.n_vocab # => is the input size of the embedding layer, ie, the size of the vocabulary\n",
    "token_embedding_dim: int = 256 # => is the output size of the embedding layer\n",
    "\n",
    "# The below parameters define the shape of the positional embedding layer\n",
    "# The positional embedding layer is of shape context_size x output_dim\n",
    "context_length: int = None # => is the length of the sequence that serves as input to the forward method of the model. It will be defined from the size of the input\n",
    "output_dim: int = token_embedding_dim # => is the size of the output of the positional embedding,\n",
    "                                      # that we want to be equal to the token_embedding_dim as this will be the input to the model\n",
    "\n",
    "# The size of the sequence to be generated\n",
    "max_length: int = 50\n",
    "\n",
    "# The stride\n",
    "stride: int = 1\n",
    "\n",
    "# Batch size\n",
    "batch_size: int = 1\n",
    "\n",
    "print(f\"Vocabulary size set to: {vocabulary_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 100 characters of the raw text:\n",
      "\n",
      "\"﻿The Project Gutenberg eBook of An open verdict\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost \"\n",
      "\n",
      "Example of text generating with context_size slicing:\n",
      "� ----> �\n",
      "� ----> �\n",
      "﻿ ----> The\n",
      "﻿The ---->  Project\n"
     ]
    }
   ],
   "source": [
    "# Example of using context with the tokenizer\n",
    "print(f\"The first 100 characters of the raw text:\\n\\n\\\"{raw_text[: 180]}\\\"\\n\")\n",
    "print(\"Example of text generating with context_size slicing:\")\n",
    "for i in range(1, 4+1):\n",
    "    context: int = tokens[: i]\n",
    "    desired: int = tokens[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=batch_size, max_length=max_length,\n",
    "    stride=stride, shuffle=True, drop_last=True,\n",
    "    num_workers=0):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# The inputs for testing\n",
    "inputs: torch.Tensor = torch.tensor([[171, 119, 123, 464],[119, 123, 464, 4935]])\n",
    "if context_length is None:\n",
    "    context_length = inputs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input embeddings: torch.Size([2, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# Initializes the embedding layers\n",
    "token_embedding_layer = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=output_dim)\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "# Runs them to check they are working\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(f\"Shape of the input embeddings: {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([1, 50])\n",
      "Targets shape: torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "# Creates the data loader\n",
    "dataloader = create_dataloader_v1(\n",
    "    txt=raw_text,\n",
    "    batch_size=batch_size,\n",
    "    max_length=max_length,\n",
    "    stride=stride,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Prints its first batch\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs shape:\", inputs.shape)\n",
    "print(f\"Targets shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMText(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            hidden_size: int\n",
    "    ):\n",
    "        '''\n",
    "        input_size: int -> size of the embedding dimension in the transformer parlance\n",
    "        hidden_size: int -> size of the hidden state\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_size: int = input_size\n",
    "        self.hidden_size: int = hidden_size\n",
    "\n",
    "        # Input gate (I):\n",
    "        # I_t = sigma(X_t.W_xi + H_t-1.W_hi + b_i)\n",
    "        # Where:\n",
    "        # X_t is X(the sequence) at time t\n",
    "        # H_t-1 is H(the hidden state) at time t-1\n",
    "        # W_xi is the weight matrix of X to I gate\n",
    "        self.W_xi: nn.Parameter = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
    "\n",
    "        # W_hi is the weight matrix of h to the I gate\n",
    "        self.W_hi: torch.Tensor = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "\n",
    "        # self.b_i is the bias to the I gate\n",
    "        self.b_i: torch.Tensor = nn.Parameter(torch.Tensor( self.hidden_size))\n",
    "\n",
    "\n",
    "        # Forget gate (F):\n",
    "        # F_t = sigma(X_t.W_xf + H_t-1.W_hf + b_f)\n",
    "        # Where:\n",
    "        # X_t is X(the sequence) at time t\n",
    "        # H_t-1 is H(the hidden state) at time t-1\n",
    "        # W_xf is the weight matrix of X to F gate\n",
    "        self.W_xf: nn.Parameter = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
    "\n",
    "        # W_hf is the weight matrix of h to the F gate\n",
    "        self.W_hf: torch.Tensor = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "\n",
    "        # self.b_f is the bias to the F gate\n",
    "        self.b_f: torch.Tensor = nn.Parameter(torch.Tensor( self.hidden_size))\n",
    "\n",
    "\n",
    "        # Output gate (O):\n",
    "        # O_t = sigma(X_t.W_xo + H_t-1.W_ho + b_o)\n",
    "        # Where:\n",
    "        # X_t is X(the sequence) at time t\n",
    "        # H_t-1 is H(the hidden state) at time t-1\n",
    "        # W_xo is the weight matrix of X to O gate\n",
    "        self.W_xo: nn.Parameter = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
    "\n",
    "        # W_ho is the weight matrix of h to the O gate\n",
    "        self.W_ho: torch.Tensor = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "\n",
    "        # self.b_o is the bias to the O gate\n",
    "        self.b_o: torch.Tensor = nn.Parameter(torch.Tensor( self.hidden_size))\n",
    "\n",
    "        \n",
    "        # Cell (C):\n",
    "        # C_t = sigma(X_t.W_xc + H_t-1.W_hc + b_c)\n",
    "        # Where:\n",
    "        # X_t is X(the sequence) at time t\n",
    "        # H_t-1 is H(the hidden state) at time t-1\n",
    "        # W_xc is the weight matrix of X to C cell\n",
    "        self.W_xc: nn.Parameter = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size))\n",
    "\n",
    "        # W_ho is the weight matrix of h to the C cell\n",
    "        self.W_hc: torch.Tensor = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "\n",
    "        # self.b_o is the bias to the C cell\n",
    "        self.b_c: torch.Tensor = nn.Parameter(torch.Tensor( self.hidden_size))\n",
    "\n",
    "        # Initializes all weights \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr: str = f\"LSTMText(input_size={self.input_size}, hidden_size={self.hidden_size})\"\n",
    "        return repr\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        stdev: float = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdev, stdev)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, states: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        assumes x.shape represents (batch_size, sequence_size, embedding_dimension)\n",
    "        \"\"\"\n",
    "        bs, sequence_size, input_size = X.size()\n",
    "        \n",
    "        if input_size != self.input_size:\n",
    "            raise ValueError(f\"Input shape: {input_size} is not equal to model input size: {self.input_size}\")\n",
    "\n",
    "        if states is None:\n",
    "            H_t, C_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(device=X.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(device=X.device)\n",
    "            )\n",
    "        else:\n",
    "            H_t, C_t = states\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(sequence_size):\n",
    "            x = X[:, t, :]\n",
    "            # I is the input gate\n",
    "            I_t = torch.sigmoid(torch.matmul(x, self.W_xi) + torch.matmul(H_t, self.W_hi) + self.b_i)\n",
    "\n",
    "            # F is the forget state\n",
    "            F_t = torch.sigmoid(torch.matmul(x, self.W_xf) + torch.matmul(H_t, self.W_hf) + self.b_f)\n",
    "\n",
    "            # O is the output state\n",
    "            O_t = torch.sigmoid(torch.matmul(x, self.W_xo) + torch.matmul(H_t, self.W_ho) + self.b_o)\n",
    "\n",
    "            # C_t, the memory (C)ell is:\n",
    "            # C_t = F(.)C_t-1 + I_t(.)C_temp\n",
    "            # C_temp = tanh(X_t.W_xc + H_t-1.W_hc + b_c)\n",
    "            C_temp = torch.tanh(torch.matmul(x, self.W_xc) + torch.matmul(H_t, self.W_hc) + self.b_c)\n",
    "            C_t = F_t * C_t + I_t * C_temp\n",
    "            H_t = O_t * torch.tanh(C_t)\n",
    "            outputs.append(H_t)\n",
    "\n",
    "        result = torch.cat([outputs[-1]], dim=0)\n",
    "        return result, (H_t, C_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 vocabulary_size: int,\n",
    "                 context_length: int,\n",
    "                 output_dim: int,\n",
    "                 out_features: int\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        # The parameters\n",
    "        self.vocabulary_size: int = vocabulary_size\n",
    "        self.hidden_size: int = hidden_size\n",
    "        self.input_size: int = input_size\n",
    "        self.context_length: int = context_length\n",
    "        self.output_dim: int = output_dim\n",
    "        self.output_features: int = out_features\n",
    "\n",
    "        # the embedding layer\n",
    "        self.token_embedding_layer: nn.Embedding = nn.Embedding(num_embeddings=self.vocabulary_size, embedding_dim=output_dim)\n",
    "\n",
    "        # the positional embedding layer\n",
    "        self.pos_embedding_layer: nn.Embedding = nn.Embedding(num_embeddings=self.context_length, embedding_dim=self.hidden_size)\n",
    "\n",
    "        # the rnn (LSTM or GRU) rnn\n",
    "        self.rnn_layer: LSTMText = LSTMText(input_size=self.input_size, hidden_size=hidden_size)\n",
    "\n",
    "        # Linear layer to generate the output\n",
    "        self.output_layer: nn.Linear = nn.Linear(in_features=input_size, out_features=out_features)\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr: str = f'''RNNModel(input_size={self.input_size},\n",
    "        hidden_size={self.hidden_size},\n",
    "        vocabulary_size={self.vocabulary_size},\n",
    "        context_length={self.context_length},\n",
    "        output_dim={self.output_dim},\n",
    "        out_features={self.output_features},\n",
    "        (token_embedding_layer)={self.token_embedding_layer}),\n",
    "        (pos_embedding_layer)={self.pos_embedding_layer},\n",
    "        (rnn_layer)={self.rnn_layer},\n",
    "        (output_layer)={self.output_layer}\n",
    "        )\n",
    "        '''\n",
    "        return repr\n",
    "    \n",
    "    def forward(self, X: torch.Tensor):\n",
    "        token_embeddings_ = self.token_embedding_layer(X)\n",
    "        pos_embeddings_ = self.pos_embedding_layer(torch.arange(self.context_length))\n",
    "        input_embeddings_ = token_embeddings_ + pos_embeddings_\n",
    "\n",
    "        output_, _ = self.rnn_layer(input_embeddings_)\n",
    "        output_ = self.output_layer(output_)\n",
    "        output_ = torch.softmax(output_, dim=-1)\n",
    "        output_ = torch.argmax(output_, dim=-1)\n",
    "        \n",
    "        return output_.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(input_size=256,\n",
       "        hidden_size=256,\n",
       "        vocabulary_size=50257,\n",
       "        context_length=4,\n",
       "        output_dim=256,\n",
       "        out_features=50257,\n",
       "        (token_embedding_layer)=Embedding(50257, 256)),\n",
       "        (pos_embedding_layer)=Embedding(4, 256),\n",
       "        (rnn_layer)=LSTMText(input_size=256, hidden_size=256),\n",
       "        (output_layer)=Linear(in_features=256, out_features=50257, bias=True)\n",
       "        )\n",
       "        "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(input_size=token_embedding_dim,\n",
    "                 hidden_size=output_dim,\n",
    "                 vocabulary_size=vocabulary_size,\n",
    "                 context_length=context_length,\n",
    "                 output_dim=output_dim,\n",
    "                 out_features=vocabulary_size)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model,\n",
    "                         idx: torch.Tensor,\n",
    "                         max_new_tokens,\n",
    "                         context_size):   \n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            output = model(idx_cond)\n",
    "        idx = torch.cat((idx, output), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you in�*=-< sans improbableorneysPacific(\" attendants funnMe sang Charl }; Return ReturndebugSports an fundamental Aidcodpatientrase knightoslav SYSTEMirable CanonPacific taggingiblings Reasons Klopp Charl }; Return ReturndebugSports an fundamental Aidcodpatientrase knightoslav SYSTEMirable\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=max_length,\n",
    "    context_size=context_length\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
