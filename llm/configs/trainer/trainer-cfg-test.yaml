name: Trainer for GPTModel
batch_size: 8
lr_rate: 0.0004
weight_decay: 0.1
num_epochs: 2
eval_freq: 100
temperature: 0.1
eval_iter: 
context_length: 1024
patience: 3
delta: 0.001
tiktoken_encoding: "gpt2"
